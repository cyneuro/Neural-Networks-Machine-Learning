# Neural-Networks-Machine-Learning
#### Notebooks in the area of Neural Networks and Machine learning. All the notebooks in this repo should have an open in colab button at the top of the notebook. 

#### *Note not all of these notebooks are finished!*

## Table of Contents
### [Gradient Descent](#gradient-descent-1)
### [Linear Regression](#linear-regression-1)
### [Logistic Regression](#logistic-regression-1)
### [PCA](#pca-1)
### [XOR](#xor-examples)
### [Convolutional Neural Network](#convolutional-neural-network-1)
### [Long Short Term Memory Networks](#long-short-term-memory-networks-1)
### [Other Network Structures](#other-network-structures-1)
### [Stats review](#stats-review-1)

## Gradient Descent
### [Gradient Descent 1](Gradient-Descent/GradientDescent1.ipynb)
* #### Notebook discussing the basics of gradient descent

### [Gradient Descent 2](Gradient-Descent/GradientDescent2.ipynb)
* #### Notebook discussing a more in depth example with gradient descent

## Linear Regression
### [Linear Regression using Gradient Descent](Linear-Regression/LinearRegressionGradDescent.ipynb)
* #### Notebook going over how to do linear regression using gradient descent by hand 

### [Linear Regression LSM Normal](Linear-Regression/LinearRegressionNumpy.ipynb)
* #### Notebook going over how to do linear regression using Least Squares Method along with using matrix theory and the normal equation

### [Linear Regression using Gradient Descent](Linear-Regression/LinearRegressionUsingPackages.ipynb)
* #### Notebook showing the different packages out there that can do linear regression. There are of course other packages that could do it, but this shows the 3 most popular

### [Linear Regression Logan's example](Linear-Regression/Data_Science_Camp_Linear_Regression.ipynb)
* #### Logan's notebook for linear regression

## Logistic Regression 
### [Logistic Regression using Gradient Descent](Logistic-Regression/LogisticRegressionGradDescent.ipynb)
* #### Notebook going over how to do logistic regression using gradient descent by hand 

### [Logistic Regression using Gradient Descent](Logistic-Regression/LogisticRegressionPyTorch.ipynb)
* #### Notebook going over how to do logistic regression using PyTorch

### [Logistic  Regression Logan's example](Logistic-Regression/LogRegressionLogan.ipynb)
* #### Logan's notebook for logistic regression

## PCA
### [PCA by hand](PCA/PCA_by_hand.ipynb)
* #### A Notebook showing how PCA works using a handmade example

### [Why PCA is important](PCA/PCA_advanced.ipynb)
* #### Shows how to do PCA using packages and shows a use case to understand how PCA can be useful

## XOR examples
### [XOR Example 1](XOR_notebooks/XOR_Example1.ipynb)
### [XOR Example 2](XOR_notebooks/XOR_Example2.ipynb)
### [XOR Example 3](XOR_notebooks/XOR_perceptron.ipynb)
### [XOR Example 4](XOR_notebooks/XOR_PyTorch_ByHand.ipynb)
### [Intro to PyTorch with XOR example](XOR_notebooks/Introduction_to_PyTorch.ipynb)
* #### In Depth how to use PyTorch with XOR as an example

## Control systems
### [Super position](control-systems/superposition.ipynb)
* #### Covers what the super position theory is and gives an example

### [Convolve](control-systems/convolve.ipynb)
* #### Gives an example of summed impulse response vs np convolve function

### [Impulse Response](control-systems/ImpulseResponse.ipynb)
* #### An example notebook showing the different types of simulus to a system

### [first vs second order system](control-systems/first_v_second_order_system.ipynb)
* #### Shows an example of different simulus to a first and second order system

### [discrete vs continuous](control-systems/discrete_vs_continuous.ipynb)
* #### shows the differences for the two types of inputs when modeling an input

## Convolutional Neural Network
### [Intro to CNN](CNN/Convolutional_Neural_Network.ipynb)
* #### An Introduction notebook to what a Convoluational Neural Network or CNN is

### [CNN PyTorch Example](CNN/CNN_PyTorch_example.ipynb)
* #### Example of how to code a CNN directly from PyTorch

### [CNN MNIST](CNN/CNNMNIST.ipynb)
* #### Another example of how to code a CNN

### [CNN with time series](CNN/Convolutional_Neural_Network_time_series.ipynb)
* #### An Example of how to use a CNN on a time series

## Long Short Term Memory Networks
### [Intro to LSTM](LSTM/LSTM.ipynb)
* #### Introduction to what an LSTM is 

### [Advanced to LSTM](LSTM/Long_Short_Term_Memory.ipynb)
* #### Advanced example of how to use a LSTM network

## Other Network Structures 
### [Intro to variational autoencoder](Other-Network-Types/Variational_Autoencoder_intro.ipynb)
* #### An introduction notebook over autoencoders

### [Variational Autoencoder example 1](Other-Network-Types/autoencoder.ipynb)
* #### An example notebook over Variational Autoencoder

### [Variational Autoencoder example 2](Other-Network-Types/Variational_AutoEncoder.ipynb)
* #### Another example notebook over Variational Autoencoder

### [Intro Recurrent networks](Other-Network-Types/Recurrent_Networks_intro.ipynb)
* #### An introduction notebook over Recurrent networks

### [RNN example](Other-Network-Types/char_rnn_classification_tutorial.ipynb)
* #### An example of how to use a RRN network

### [GAN network example1](Other-Network-Types/gan.ipynb)
* #### An example how to make a gan network

### [GAN network example2](Other-Network-Types/DCGAN.ipynb)
* #### An example how to make a gan network

### [Random Forest Trees](Other-Network-Types/RF_Trees.ipynb)
* #### Notebook over random forest trees


## Stats review
### [Information and Entropy](stats/InformationAndEntropy.ipynb)
* #### A notebook reviewing those two stats topics

### [KL Divergence and Cross Entropy](stats/KLDivergenceAndCrossEntropy.ipynb)
* #### A notebook reviewing those two stats topics

### [Covariance](stats/KLDivergenceAndCrossEntropy.ipynb)
* #### A notebook reviewing covariance

### [Maximum Likelihood Estimation](stats/Maximum_Likelihood_Estimation.ipynb)
* #### A notebook reviewing maximum likelihood estimation (MLE)

### [Different distribution](stats/Probability_Noise_PSD_example.ipynb)
* #### A notebook showing how to generate different distributions and small details about each distribution






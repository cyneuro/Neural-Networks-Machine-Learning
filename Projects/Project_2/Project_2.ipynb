{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cyneuro/Neural-Networks-Machine-Learning/blob/master/Projects/Project_2/Project_2.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frpo2i8JqPwf"
      },
      "source": [
        "**PROJECT 2**\n",
        "\n",
        "(i) Develop a Colab tutorial to illustrate the concept of probability distributions of following types with examples – normal/Gaussian, exponential, Poisson.\n",
        "\n",
        "(ii) Spikes arriving at a neuron typically is a Poisson process. The firing of a neuron is often modeled also as a Poisson process. Download this in vivo spike data, show that the spiking of a neuron is a Poisson process (OR NOT) by fitting a Poisson distribution to the number of spikes within a time window. Also show that the inter-spike intervals follow an exponential distribution (OR NOT). Plot both the histogram of data samples and the fit distribution curve in the same figure. Include all codes you use to process the data in a notebook, keeping all results, and explain your findings in markdowns. Note the followings:\n",
        "\n",
        "1. Data description: The data is downloaded from a public dataset hc-3 which contains LFP recordings from hippocampal areas of rats. This (http://crcns.org/data-sets/hc/hc-3/about-hc-3) website provides an overview of the dataset. The spike data you need is in the two folders \"ec012\" and \"ec016\" in the zip folder you downloaded, each recorded from a rat. In each folder, there are several data files with name format \"xxxxx.yyy.res.zz\", where xxxxx is the id of a rat, yyy is the session id and zz is a neuron id. There are two neurons for each session. The files can be opened or read in programs as text files. There is one single column in each file recording the spike times. Each value in the column is an integer of the time index in the recording of a session. The sampling rate is 20kHz, so each time step is 0.05 ms. You are required to check all the 14 files provided. You don't need to show results for all but choose at least THREE, which you think can represent a variety of cases among them.\n",
        "\n",
        "2. You need to use maximum likelihood estimation (MLE) to fit the distributions to your data samples. Then calculate the mean of the data samples and compare it with the resulting distribution parameter and check whether they agree, i.e. to show that the MLE for fitting Poisson distribution and exponential distribution is equivalent to simply calculating the sample mean.\n",
        "\n",
        "3. When you fit Poisson distribution to the number of spikes, different selection of time interval length may result in different distribution. Some cases may fit well to Poisson, some may not. You can use Fano factor (variance/mean) to evaluate whether its close to Poisson distribution. Poisson distribution has a Fano factor that equals 1. Do summarize what you found when you try different time intervals. Also, when you fit exponential distribution to inter-spike intervals and find it does not fit well, try to explain why.\n",
        "\n",
        "4. (Optional) Explore more data from on this public dataset (Links to an external site.). You can find two pdf documents with detailed explanation of the dataset in the zip folder you downloaded. The rats were performing different behavioral tasks in different sessions. You can find a list of info for each session in the file hc3-session.csv. The spike time data is in the files with \"res\" in their name. You can explore with more data how the spike statistics differ in different neurons, under different behavioral tasks. You should note what is different about the new dataset that you chose, and what is different about the new poisson fit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJs-dYRcqpEV"
      },
      "source": [
        "# (i) Probability Distributions\n",
        "\n",
        "A probability distribution is the mathematical function that gives the probabilities of occurrence of different possible outcomes for an experiment. This distribution describes a random variable by associating a probaility with every possible outcome across the entire sample space. This distribution can either be discrete (probability mass function, PMF) or continuous (probability density function, PDF), depending on whether the variable it describes takes on discrete or continuous values. Random variables can be described by a probability distribution of any shape, but a large majority of variables have probability distributions belonging to one of several common stereotyped classes which we shall explore here.\n",
        "\n",
        "Adapted from: https://en.wikipedia.org/wiki/Probability_distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbDebwNI2vzo"
      },
      "source": [
        "The most common probability distribution is the normal or gaussian pdf. This distribution is symmetric across its average/mean value. The width or spread of the distribution is described by its standard deviation. Mean and std are represented by the greek letters μ and σ. A gaussian distribution is described by the equation:\n",
        "\n",
        "\\begin{align}\n",
        "f(x)= {\\frac{1}{\\sigma\\sqrt{2\\pi}}}e^{- {\\frac {1}{2}} (\\frac {x-\\mu}{\\sigma})^2}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "UA4RzM5JqNcG",
        "outputId": "04ae5a19-0dac-4dfb-8757-ddf25bca826a"
      },
      "outputs": [],
      "source": [
        "# Generate random samples from a gaussian distribution\n",
        "from scipy.stats import norm\n",
        "size = 1000 # num of points\n",
        "n = norm.rvs(loc=0, scale=1, size=size) # mean = 0, std = 1\n",
        "\n",
        "# Plot histogram and probability density function (pdf)\n",
        "import matplotlib.pyplot as plt\n",
        "_, bins, _ = plt.hist(n, bins=30, density=True)\n",
        "plt.plot(bins, norm.pdf(bins), 'r')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.xlabel('X')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIwNWord5Y2f"
      },
      "source": [
        "Another common distribution is the exponential distribution. This distribution is defined by a single rate parameter lambda (λ). This distribution also represents the time between events occuring in a poisson process, the next distribution we shall discuss. The distribution is described by the equation:\n",
        "\n",
        "\\begin{align}\n",
        "f(x) = \\begin{cases} \\lambda e^{-\\lambda x} & x\\geq 0 \\\\ 0 & x<0 \\end{cases}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "df6bQ7iY3bz4",
        "outputId": "25fad613-2651-4573-fa35-e0b74a1410ac"
      },
      "outputs": [],
      "source": [
        "# Generate random samples from an exponential distribution\n",
        "from scipy.stats import expon\n",
        "e = expon.rvs(scale=1, size=size) # lambda = 1\n",
        "\n",
        "# Plot histogram and pdf\n",
        "_ , bins, _ = plt.hist(e, bins=30, density=True)\n",
        "plt.plot(bins, expon.pdf(bins), 'r')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.xlabel('X')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwr3EFBC5pI2"
      },
      "source": [
        "Finally, the poisson distribution is a means of describing the probability of a given number of events occurring in a fixed interval of time or space, assuming these events occur with a known constant mean rate (λ). Since events either occur or do not occur, the poisson distribution describes a discrete random variable and is therefore a probability mass function. A poisson distribution is described by the following equation:\n",
        "\n",
        "\\begin{align}\n",
        "\\!f(k)=\\frac{\\lambda^k e^{-\\lambda}}{k!}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "a2kBYgWk3lbQ",
        "outputId": "78066ff1-000f-485c-8d3a-712d47302191"
      },
      "outputs": [],
      "source": [
        "# Generate random samples from a poisson distribution\n",
        "from scipy.stats import poisson\n",
        "lam = 10\n",
        "p = poisson.rvs(mu=lam, size=size) # lambda = 5, note: lambda = mu in a poisson distribution\n",
        "\n",
        "# Plot histogram and pmf\n",
        "bins = range(max(p))\n",
        "plt.hist(p, bins=bins, density=True)\n",
        "plt.plot(bins, poisson.pmf(bins,lam), marker='o', color='r')\n",
        "plt.ylabel('Probability Mass')\n",
        "plt.xlabel('X')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of4_6TiV9O_K"
      },
      "source": [
        "# (ii) Modeling the Firing of a Neuron as a Poisson Process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqCw9o65ovwf"
      },
      "source": [
        "# Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUiR-DAL9URT",
        "outputId": "ef851551-36dc-4b7b-b627-2822ca8590d1"
      },
      "outputs": [],
      "source": [
        "# clone github repo with the data\n",
        "RunningInCOLAB = 'google.colab' in str(get_ipython()) \n",
        "if RunningInCOLAB:\n",
        "    # clone github repo with the data\n",
        "    !git clone https://github.com/cyneuro/Neural-Networks-Machine-Learning.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivgXLOvRFtEh"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Here we will read all of the provided spike data into two arrays, one for each folder\n",
        "Dictionaries can be indexed by filename to access spike data\n",
        "Note: For a given file \"xxxxx.yyy.res.zz\", xxxxx = ratID, yyy = sessionID, and zz = neuronID\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import os  # Import the os module\n",
        "\n",
        "fs = 1 / 20000 # 20kHz # converted to sampling period\n",
        "\n",
        "def get_spikes(filename, fs):\n",
        "    with open(filename) as f:\n",
        "        data = f.read()\n",
        "        data = data.split()\n",
        "        return np.array(data).astype(float) * fs # scale spike times by sampling frequency\n",
        "\n",
        "# Change directory to the first folder\n",
        "base_path = os.getcwd()\n",
        "os.chdir(base_path+'/ec012')\n",
        "filenames = ['ec012ec.187.res.1', 'ec012ec.228.res.1', 'ec012ec.375.res.1',\n",
        "             'ec012ec.187.res.2', 'ec012ec.228.res.2', 'ec012ec.375.res.2']\n",
        "\n",
        "spikes_ec012 = {filename: get_spikes(filename, fs) for filename in filenames}\n",
        "\n",
        "# Change directory to the second folder\n",
        "os.chdir('../ec016')  # Assuming ec012 and ec016 are in the same directory\n",
        "filenames = ['ec016.272.res.1', 'ec016.457.res.1', 'ec016.674.res.1', 'ec016.682.res.1',\n",
        "             'ec016.272.res.2', 'ec016.457.res.2', 'ec016.674.res.2', 'ec016.682.res.2']\n",
        "\n",
        "spikes_ec016 = {filename: get_spikes(filename, fs) for filename in filenames}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyIJzxpGo7QS"
      },
      "source": [
        "# Fit Distributions to Experimental Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-y9VdMPecBx",
        "outputId": "83bf7ceb-98e0-4dd6-a163-6fc2a5a02b88"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "In this block I create some functions which we will use to fit poisson distributions\n",
        "to our data. More specifically, we will examine the distribution of spikes per unit time\n",
        "(a variable dt of our choosing). We will use Maximum Likelihood Estimation to calculate our parameter lambda.\n",
        "\"\"\"\n",
        "\n",
        "from math import ceil\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# Use np.histogram to find the number of spikes within each time segment of length dt\n",
        "def spike_per_time(spikes,dt):\n",
        "    t_segs = np.arange(0, ceil(spikes[-1]), dt)\n",
        "    spt, _ = np.histogram(spikes, bins=t_segs)\n",
        "    return spt, dt\n",
        "\n",
        "# Calculate negative log likelihood based on a poisson distribution\n",
        "def poissonNLL(lam):\n",
        "    return -np.sum(poisson.logpmf(spt, mu=lam))\n",
        "\n",
        "def get_poisson_param(spt):\n",
        "\n",
        "    # Find value of lambda that minimizes the log likelihood\n",
        "    lam_MLE = minimize(poissonNLL, 1, method='Nelder-Mead').x[0] # lam_init = 1\n",
        "\n",
        "    # Estimate lambda with a simple average\n",
        "    lam_AVG = sum(spt) / spt.size\n",
        "\n",
        "    return lam_MLE, lam_AVG\n",
        "\n",
        "filename = 'ec012ec.228.res.1'\n",
        "spikes = spikes_ec012[filename]\n",
        "spt, dt = spike_per_time(spikes,0.1)\n",
        "lam_MLE, lam_AVG = get_poisson_param(spt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "deuP8aqTzARl",
        "outputId": "5f0c4c9f-f654-45ba-ebb6-88eb4563dc87"
      },
      "outputs": [],
      "source": [
        "# Plot Results\n",
        "\n",
        "def plot_poisson_dist(spt,lam_MLE,lam_AVG,title,dt,fsize):\n",
        "    plt.figure(figsize=fsize)\n",
        "    _, bins, _ = plt.hist(spt, bins=30, density=True)\n",
        "\n",
        "    x = range(round(max(bins)))\n",
        "\n",
        "    p_MLE = poisson.pmf(x, lam_MLE)\n",
        "    plt.plot(x, p_MLE, linewidth=3, color='g', label='MLE')\n",
        "\n",
        "    p_AVG = poisson.pmf(x, lam_AVG)\n",
        "    plt.plot(x, p_AVG, linewidth=2, linestyle='--', color='r', label='Average')\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Probability Mass')\n",
        "    plt.xlabel('Spikes per %.3f sec' % dt)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_poisson_dist(spt,lam_MLE,lam_AVG,filename,dt,(16,5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "gidxoSC03HDy",
        "outputId": "ff21ada2-535f-4f88-e256-85cd3642fc70"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Here we will write similar functions to fit an exponential function to a new subset of our data,\n",
        "the interspike time interval. Once again, the parameter lambda which determines the shape of this function is\n",
        "calculated with MLE and then compared to another value of lambda calculated as a simple average.\n",
        "\"\"\"\n",
        "\n",
        "def get_spike_intervals(spikes):\n",
        "    return np.array([spikes[i+1] - spikes[i] for i in range(spikes.size-1)])\n",
        "\n",
        "# Calculate negative log likelihood based on an exponential distribution\n",
        "def exponNLL(lam):\n",
        "    return -np.sum(expon.logpdf(spaces, scale=1/lam)) # scale = mu = 1 / lam\n",
        "\n",
        "def get_expon_param(spaces):\n",
        "    # Find value of lambda that minimizes the log likelihood\n",
        "    lam_MLE = minimize(exponNLL, 1, method='Nelder-Mead').x[0] # lam_init = 1\n",
        "\n",
        "    # Estimate lambda with a simple average (inverse)\n",
        "    lam_AVG = spaces.size / sum(spaces)\n",
        "\n",
        "    return lam_MLE, lam_AVG\n",
        "\n",
        "def plot_expon_dist(spaces,lam_MLE,lam_AVG,title,fsize):\n",
        "    plt.figure(figsize=fsize)\n",
        "\n",
        "    _, bins, _ = plt.hist(spaces, bins=30, density=True)\n",
        "\n",
        "    x = np.linspace(0,max(bins),100)\n",
        "\n",
        "    e_MLE = expon.pdf(x, scale=1/lam_AVG)\n",
        "    plt.plot(x, e_MLE, linewidth=3, color='g', label='MLE')\n",
        "\n",
        "    e_AVG = expon.pdf(x, scale=1/lam_AVG)\n",
        "    plt.plot(x, e_AVG, linewidth=2, linestyle='--', color='r', label='Average')\n",
        "\n",
        "    plt.legend()\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.xlabel('Interspike Interval (s)')\n",
        "    plt.show()\n",
        "\n",
        "spaces = get_spike_intervals(spikes)\n",
        "lam_MLE, lam_AVG = get_expon_param(spaces)\n",
        "plot_expon_dist(spaces,lam_MLE,lam_AVG,filename,(16,5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yaDNVFLMuuNd",
        "outputId": "7451c582-2c2e-49e7-f5bf-ef81e244bdb3"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "\"\"\"\n",
        "# The Fano Factor (FF) is a simple metric used to measure the dispersion of a distribution\n",
        "# A poisson process will have FF = 1, thus each distribution's FF will represent a measure of\n",
        "# how closely it fits to a poisson process. The closer to 1, the better the fit.\n",
        "\"\"\"\n",
        "def get_fano_factor(data):\n",
        "    _, _, mean, variance, _, _ = stats.describe(data)\n",
        "    return variance / mean\n",
        "\n",
        "def fit_poisson_dist(spikes, dt, filename):\n",
        "    global spt # quick fix to ensure get_poisson_param has access to latest spt\n",
        "    spt, dt = spike_per_time(spikes, dt)\n",
        "    lam_MLE, lam_AVG = get_poisson_param(spt)\n",
        "    title = filename + (' (Fano Factor = %f)' % get_fano_factor(spt))\n",
        "    plot_poisson_dist(spt, lam_MLE, lam_AVG, title, dt, (10,3))\n",
        "\n",
        "def fit_expon_dist(spikes, filename):\n",
        "    spaces = get_spike_intervals(spikes)\n",
        "    lam_MLE, lam_AVG = get_expon_param(spaces)\n",
        "    plot_expon_dist(spaces, lam_MLE, lam_AVG, filename, (10,3))\n",
        "\n",
        "# Quick Examination of Procedure applied to all samples\n",
        "for fname in spikes_ec012.keys():\n",
        "    spikes = spikes_ec012[fname]\n",
        "    fit_poisson_dist(spikes, 0.1, fname)\n",
        "    fit_expon_dist(spikes, fname)\n",
        "\n",
        "for fname in spikes_ec016.keys():\n",
        "    spikes = spikes_ec016[fname]\n",
        "    fit_poisson_dist(spikes, 0.1, fname)\n",
        "    fit_expon_dist(spikes, fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am9cj5hIBYrv"
      },
      "source": [
        "The following block of code examines 3 different samples and how well they can be estimated as poisson processes.\n",
        "* The first sample matches our intuitions quite well. When plotting the distribution of spikes in our selected time window (0.1 sec), we measure a Fano Factor of ~1.20. This is one of the best fits we see across all of our data. We can safely assume that it can be modeled as a poisson process. The plot of the distribution of interspike intervals also fits quite well with the exponential function we calculated with MLE.\n",
        "* This sample does not offer quite the same caliber of results. Here we can see that the same window size of 0.1 sec does not produce results that match a poisson process. However, we can improve our approximation by choosing a smaller window. A window of 25 msec produces a distribution which begins to look more like a poisson process, but with a FF ~= 4.06, this approximation is a bit of a stretch.\n",
        "* The final sample demonstrates a case in which our distribution is heavily concentrated near zero. By altering our window size, we can once again acheive a very loose approximation with a FF ~= 4.28, but this is certainly not as accurate of an approximation as we achieved with the first example.\n",
        "\n",
        "While some data sets don't perfectly match a poisson process, I think that if we take into consideration a large number of samples over a long enough period of time, it is a reasonable assumption to consider the firing of a neuron to be a poisson process. Thus we also must consider the interval of time taking place between spikes to follow an exponential distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CdZQ8OEZ1uNP",
        "outputId": "6cd6a05e-901a-4c6f-c739-578c4aa650ca"
      },
      "outputs": [],
      "source": [
        "# Cases of Particular Interest\n",
        "\n",
        "fname = 'ec012ec.187.res.2'\n",
        "spikes = spikes_ec012[fname]\n",
        "fit_poisson_dist(spikes, 0.1, fname)\n",
        "fit_expon_dist(spikes, fname)\n",
        "\n",
        "fname = 'ec016.272.res.1'\n",
        "spikes = spikes_ec016[fname]\n",
        "fit_poisson_dist(spikes, 0.1, fname)\n",
        "fit_expon_dist(spikes, fname)\n",
        "fit_poisson_dist(spikes, 0.025, fname)\n",
        "fit_expon_dist(spikes, fname)\n",
        "\n",
        "fname = 'ec016.674.res.1'\n",
        "spikes = spikes_ec016[fname]\n",
        "fit_poisson_dist(spikes, 0.08, fname)\n",
        "fit_expon_dist(spikes, fname)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "bmtk",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
